const data = [
    {
        title: 'Could we recognize a conscious machine?',
        count: 3302,
        content: ['Supposed that a computer scientist claims that he has successfully managed to invent a conscious computer and we who have zero knowledge of it yet are invited to interact with it and verify whether his claim is true. What tools do we have to make our verification here? Namely, what criterion would we use when we are thinking about consciousness? We may start to select some unique properties of consciousness which could hardly be simulated by other substances and therefore seems to be good criteria for most of us intuitively to judge consciousness in the computer.',

            'In this short essay, we select and analyze the following criteria one by one to find out the valid and invalid ones: reasoning and creativity, functionalism, intentionality, and subjectivity. At the end of the essay, we will conclude that functionalism may be the only valid criterion while others are not as proper as we expected. Even so, we are still far away from judging whether a computer is conscious. ',

            'We may ask the claimed conscious computer to play board games to check its ability of reasoning and creativity due to the following reasons.',

            'Board games have various delightful properties which make them an important and famous index of the ability of reasoning and creativity of computers. Here we take chess and Go as specific examples. Firstly, their histories are long enough that genius human grandmasters already found numerous useful strategies to handle different situations based on their understanding. Therefore, creating new strategies that are better than what we already have and use them to beat the human player could show the creativity of computers. Secondly, the rules and the component of chess games are relevantly simple and regular. Hence, they are easily transported to and represented by computers. Thirdly, under these simple rules and components, chess and Go surprisingly give us the complexity from the different positions of the pieces. The total number of possible moves of Go is larger than the total number of atoms in our observable universe. Thus, no powerful computer can win simply by storing all possible movements and choosing the best one to move. Instead of an exhaustive method, the right way to gain success principally for computers is that analyzing the next few movements including the possible responses of the opposite based on the current situation, and choose a relevant good one to move, which could show the ability of reasoning. In other words, creating some new strategies that humans unable to recognize in the past few thousands of years shows the ability of creativity, and choosing the best move based on the current situation of the pieces shows the ability of reasoning.',

            'In the development history of board-game-playing computers, there were two milestones moments. At the same time, unfortunately, these two realistic cases also indicate that the criterion is nearly not convincible at all or at least not as convincible as our expectation.',

            'The first milestone is that Deep Blue developed by IBM defeated Garry Kasparov, the reigning world champion, in 1997. It was the first time that a computer won a chess game against the world-leading human players under regular time controls. The second one is that Alpha Go designed by Deep Mind beat Ke Jie, the top Go player all over the world till now, in May 2017. It was also inspired that almost everyone who has the concept of the complexity of Go including those who are not experts to Go has concluded that computers could hardly handle it. Although these two computers shared few common searching methods and used completely distinct computational architectures, they still achieve their goal and help humans find out some new playing strategies. ',

            'But clearly, most people will not consider the Deep Blue or Alpha Go are conscious. Hence, if the claimed conscious computer could show its creativity and reasoning in the broad games (even as complex as Go) through beating the best human player in the world and bringing some edge perspectives in this field like the above two computers, it seems that we still not confident enough to conclude that the computer is conscious. What we might do probably is only being surprised by its playing skills but not attributing consciousness to it. So, the reasoning and creativity of broad games could not be a good criterion for our judgment.',

            'Someone may argue that broad game is only a trivial and relevantly simple part of the entire human activities. What if the claimed conscious computer shows general reasoning and creativity ability instead of reasoning and creativity in the board games? Besides creating new strategies and choosing the best move, it could also create some new proofs of existed theorems or even propose new theorems or arguments and determine the correctness of some given theorems or arguments in the fields of mathematics, physics, or even philosophy simultaneously? Unfortunately, although we must admit that the question/answer spaces, searching methods, driven rules are extremely different between these subjects and board games are different, there are no essential differences between them. So, it might be difficult for computer scientists to build such a philosophy computer and make it run correctly, but there is no extra consciousness this computer could produce other than the board game computer. In addition, we could hardly guarantee the generality in the argument. It is impossible for us to test infinite tasks on the computer to check its general reasoning and creativity. ',

            'We then change our view into functionalism. The functionalists claim that what makes something a mind does not depend on its internal structure, but rather on the way it functions.',

            'Turing Test gives us a good implementation of the perspective of functionalists. Turing Test is a thought experiment proposed by Alan Turing in 1950. Suppose that a computer and a human are placed respectively in two different rooms without any interaction between them. Human outside the rooms served as judges are trying to distinguish them by asking them arbitrary questions and analyzing their responses. After a few rounds, they will draw a conclusion about which one is a computer while the left one is a human. The number of judges should be large and if the total correctness of these human judges is close to random picks, in other words, human judges are not able to distinguish the computer from the human, we may conclude that the computer has passed the Turing Test. Turing suggested that a computer that passed the Turing Test is conscious. ',

            'The principle in the Turing Test is basically functionalism and quite intuitive. Supposed that when we interact with extraterrestrial civilization in the future (if it exists), it will be hard to reject the consciousness of the aliens who act intelligently like us only because they have different components from us. The same intuition could be applied to computers. In Turing\'s paper, he proposed that the only evidence we have that other people are conscious are the ways they communicate with us. A Turing-passed computer is communicating with us in the same way. Hence, we have the same evidence that the Turing-passed computer and other people are both conscious. ',

            'The likeness in the functionalism shows a bridge that connects two seemingly different things into one fundamentally same thing. It is definitely possible that what the computer is showing is only as-if consciousness. But from the same skeptic view, it is also possible that the sense that we ourselves are conscious is an illusion and we also only have as-if consciousness before we could find out what type of consciousness we have. I will tend to conclude that the relationship between these two kinds of consciousness is like the relationship between our consciousness and the consciousness of apes and dolphins. To simplify it, they are different in levels but not in categories. Hence, if we are convinced by functionalism, we could conclude the claimed conscious computer is conscious when it behaves like a conscious person. ',

            'Also, it may be possible for us to check whether the claimed conscious computer has intentionality. We first define intentionality and explicitly programmed computer which are useful in the following discussion with Searle\'s argument. Intentionality is the aboutness in our minds, the ability to represent, the correspondence between mental state and in the outside world. An explicitly programmed computer is a computer that requires programmers to consider every possible situation it may meet and write codes according to those distinct situations, which is how most programs and computers work nowadays such as the Word I am using currently provided by Microsoft. For an explicitly programmed computer, Searle argues that it cannot have intentionality even if it pretends to do so. ',

            'The Chinese Room Argument was a thought experiment proposed by John Searle in 1980. Supposed that a native English speaker who does not know any Chinese is locked in a room. In the room, a large book that consists of many roles written in English enables him to correlate one set of Chinese symbols with another set. A native Chinese speaker outside the room writes a letter and sends it inside the room. In the room, the English speaker uses that book to manipulate the Chinese symbols on the letters and produces another Chinese letter as a reply. In principle, if the rules in the book complete enough, he could convince the Chinese speaker that there is a Chinese sit in the Chinses Room after he sends back the letter. Although the English speaker could produce an impeccable Chinese output to any Chinese inputs in principle by manipulating uninterrupted symbols, he does not understand Chinese but only simulates to do so. Follow this analogy, Searle suggests that the book with the roles here is \'program\' while the person here is \'processor\' and the whole system could be accounted for \'computer\'. ',

            'After explaining the Chinese Room and its relationship with the computer, Searle responds to the so-called System Reply. It proposes that the individual person locked in the room is only a part of the whole system. If we consider the whole room as a system including the book, the pencils, and the person, this whole system does understand Chinese. Searle\'s rejection of System Reply is that lets the individual internalize all these elements of the system by memorizing all rules in the books and doing the calculation by heart and obviously he still does not understand Chinese. ',
            'My reply to the Chinese Room Argument will be based on the System Reply. The symbols in the book will no longer be meaningless if their meanings have been discovered by connecting with the outside world. If we turn the implicit correspondence between the roles in the book and the outside world into explicit ones, the understanding surprisingly appears. ',

            'After the person in the System Reply who has memorized all the rules walks outside the Chinese Room and talks (we can assume that talking and writing are equivalent with the help of the role book) to the native Chinese speaker, he may start to link one rule in the books to one substance in the outside world. One simple example is that the native Chinese speaker says, \u82b1 in Chinese when pointing to a branch of flowers. The roles memorized and the calculation done by the locked man\'s mind will enable him to reply to some sentences he does not understand currently. But repeating this situation many times such as the native Chinese speaker points to different flowers when saying some similar sentences (every word might change excluding the \u82b1), the locked person will finally realize that \u82b1 in Chinese is correspondent to the flowers in the outside world even if he still does not understand his Chinese response and all other words in those sentences. What happens here is that the native Chinese speaker successfully helps the locked person build the explicit relationship between the flower in the reality with the Chinese word \u82b1, which was buried in the roles of the books when he was locked in the Chinese Room. Once all the correspondences have been fully established, the symbols in the roles are no longer mystery for him, and the intentionality will occur. He finally gains the understanding of Chinese. ',

            'In order words, the alone manipulation symbol system itself can never have the understanding but we may say it has when it successfully builds some kind of connection in some ways (even it maybe is totally different from how we human represent the world in our mind and therefore could hardly be interpreted by us) between its inner roles and the outer world.',

            'It is clear that the manipulation symbol system (computer) described in Searle\'s paper (even he does not point out) is an explicitly programmed computer we defined above or so-called Good Old-Fashioned Artificial Intelligence (GOFAI). The connectionists are considering and developing a new kind of computer (or a new way of programming), which is totally different from GOFAI. What they concentrate on is machine learning or even further, deep learning. However, I will argue that the Chinese Room Argument is also applicable to connectionism. ',

            'We first interpret the workflow of machine learning. Before training the neural network, computer scientists only set up some parameters to make sure the result in the matrices convergent after training and the loss function to let the program know how far its performance from its purpose.  Then, in the training process, the neural network uses backpropagation to update the elements in its matrices. Computer scientists will not explicitly program the computer about how to perform but let the computer find out the pattern by itself after numerous iterations. ',

            'It is safe to conclude that the only principal difference between the NN computer and the GOFAI is that the NN could gain the roles which are equivalent or even better than the roles given by computer scientists by itself. Following the analogy given by Searle, the GOFAI uses the books provided by programmers in the Chinese Room while NN studies and writes the roles by itself through the backpropagation technique. And the rest of the workflow is the same for both. Both are still manipulation symbol systems. So, there is still no intentionality in the NN computer.',

            'No matter the claimed conscious computer is a GOFAI-type or a connectionism-type computer and considering my reply to the Chinese Room Argument, we still can hardly distinguish whether the computer has intentionality. Once it claims that it already has all the correspondences between its inner mental world and the outer world (i.e. it successfully links its symbols to the entities in the outside world), we may conclude that it has the intentionality based on my reply. Unfortunately, from our perspective, there is no other way apart from its self-claiming to know whether the correspondence has been built successfully and fully. We could not distinguish between the case that the computer pretends to do so and the case that it really successes. Therefore, intentionality is also not a good criterion for us to judge. ',

            'Finally, we may try to use subjectivity as the criteria to determine whether the claimed conscious computer is conscious. The subjectivity discussed here is associated with Other Minds problem and skepticism. ',

            'The thought experiment Brain in a Vat is widespread in literature like Meditations on first philosophy and movies The Matrix. The common feature is that a mad scientist, evil demon, machine, or other entity which the brain in the vat is unaware of connects the brain\'s neurons by wires to an external supercomputer or uses other ways in order to mislead the brain from its real circumstance. The brain may think of itself walking on the beach under sunshine while it is suspended in a vat with cold liquid.',
            'The idea behind the Brain in a Vat is the skeptical view of everything apart from our own subjectivity, which also includes other minds. We never experienced the subjectivity of others under current technology. \'What is it like to be other?\' is very mysterious for us. The only way we currently have to know how others feel is through their expression. Take a simple example of the qualia of sadness. I have no idea of the extent of sadness when my friend is crying after losing a basketball game. It is hard to assess whether the sadness he has is the same as I have when I lost my pen (slighter) or I fail my exam (more serious). It is not only the extent matters but also the sad experience itself that is distinct from each other. He might go through the sadness in a completed different way from mine, such as feeling the scene darker and the noise louder while I may feel my body colder and speak tremblingly. He might try to describe his feeling as detail as he can, but I am still far away from \'feel what he feels\'.',

            'More generally, it is metaphysically possible that some people around us are philosophy zombies. Instead of having a different experience from us under the same behavior, they do not have any mental experiences at all. They act the same as us, which means we could hardly figure them out by any forms of interaction including communication. This skeptical idea may bring us further to the stage of solipsism, in which Descartes concluded that the only convinced thing for him is the existence of himself. The inaccessibility of subjectivity makes it a useless criterion.',

            'Someone may reply that it is because of the technology restriction. If the technique is fully developed in the future, we could access other\'s subjectivity and smoothly use it to judge the consciousness of the computer. I will argue that this is principally impossible.',

            'Thomas Nagel augurs that subjectivity is something that could not be explained and approached by objective means. The characterized subjectivity is only for individuals and could not be experienced by others. No matter how hard I try to imagine the bet\'s point of view by imaging using ultrasound in the dark environment and waving our wings, I still have a clear understanding and memory that I am a human. I could never reduce the subjectivity of a human being in this circumstance. The only way to be a bet and know what it is like is to remove all subjectivity I currently have (if this inhuman surgery is possible) and instill the experience of a bet in my brain. However, the method presented here is meaningless. The subjectivity I have is strongly connected to the concept of myself. I can only build my unique and distinct mental experience using the foundation of the self-recognition. Once my subjectivity has been removed, the existence of myself will also fade. In other words, I cannot have two subjectivities simultaneously. It shows that there is a tremendous gap of subjectivity between me and bets or other people who have more similarities than bets with me.',
            'Hence, we could conclude that there is no chance for us to get even one piece of the subjectivity of the claimed conscious computer (no matter it has or not). So, the inaccessibility makes this criterion invalid. ',

            'After evaluating all those intuitively persuaded four criteria, we may find that functionalism is somehow the only valid criterion while others are hard to achieve or invalid.',

            'From a materialist\'s point of view, I believe that at some stages in our future, we will get used to the non-human consciousness around us and understand that the consciousness is nothing special but only an inevitable result from complexity and proper implementation of some specific materials. The functionalism could be applied more easily and convincingly after we have and clearly verify the above understanding. Before verifying that, we are still far away from recognition of whether a computer is conscious.'],
    },
    {
        title: 'Programs and Our Consciousness',
        count: 1823,
        content: ['In the philosophy of consciousness, what we must first admit without any doubts is that we ourselves do have consciousness. Then, we attribute consciousness to other people around us or even apes and dogs based on some implicit assumptions. Finally, we may consider that a computer which is complex enough could have inner mind with consciousness. It is a quite natural path with a few steps when we considering consciousness. In this short essay, I will argue this consciousness path step by step in order to show that there are some defects in the consideration. ',
            'We may start focusing on whether consciousness could be contained in computers. Turing supported this idea in Turing Test while Searle denies it by proposing Chinese Room Argument.',

            'Turing Test is a thought experiment proposed by Alan Turing in 1950. Suppose that a computer and a human are placed respectively in two different rooms. Another human as judge outside the rooms is trying to figure out which one is computer only by communicating with them. If the total correctness of many human judges is close to random picks, then we may conclude that the computer has passed the Turing Test. In Turing\'s opinion, we could claim that this computer has consciousness.',

            'The test works well based on the Turing\'s Same Evidence Argument. In this argument, he proposed that the only evidence we have that other people are conscious are the ways they communicate with us. Then, a Turing-passed computer communicates in the exact same way. Hence, we have the same evidence that the Turing-passed computer and other people are conscious. Other than a computer, if Turing found an alien who could communicate with him in the same way other people do, he may also suggest that it has the same properties of mind as human.',

            'Back to the Turing Test case, Turing never considered the differences between human\'s brain and computer\'s processor, and only focused on their performances. We could easily see that the idea behind the Turing Test is functionalism. Functionalists believe in that anything that has the functional role of a mind is a mind, which means that the structures or materials inside is unnecessarily considered.',

            'In fact, Turing Test and functionalism are very intuitive and natural. It could be shown in the following Documentary Hypothesis. Supposed that an advanced civilization is making a documentary for the entire human society, which is basically the same as what we did on African lions. They bring numerous androids as cameras to the Earth. These androids only follow instructions and upload their recording in their daily routine living around us. They act very similar to normal people, which means we could hardly figure them out by any forms of interaction. Also, under our current detection technology, we could not find any difference between them and normal biological human, which means that we cannot find them out by any physical methods. Then, we could see that we are running the Turing Test constantly in our daily lives on people living around us. And all of them indeed have passed it till this moment. The only difference here is that we are never told that some of them are computers.',

            'This alternative Turing Test brings us to the remix of the Combination Reply and the Other-Mind Reply to the Chinese Room Argument. These two replies will be mainly discussed after explaining the argument.',

            'The Chinese Room Argument was a thought experience proposed by Searle in 1980. Supposed that a native English speaker who has zero knowledge of Chinese is locked in a room. In the room, a book which consists a large number of roles written in English enables him to correlate one set of Chinese symbols with another set. The book here is \'program\' while the man here is \'processor\' and the whole system could be accounted as \'computer\'. Although the man could produce an impeccable Chinese output to any Chinese inputs in principle by manipulating uninterrupted symbols, he does not understand Chinese at all. In addition, Searle concludes that no intentionality is contained in the symbol manipulation or so-called computational processes.',

            'Searle uses this argument to object the Turing Test and the functionalism behind it. In my personal perspective, he does success to some extent. There is no understanding in the symbol manipulation system even we could not figure out the difference between its outputs and human\'s. In other words, there is inner difference between them which could not be found by only checking the outputs. It is strongly against the Turing Test. It notices us that we should be careful when attributing mental states to the digital computers with sort of programs.',

            'However, the objection against functionalism in the argument is not as strong as the above ones. In the comments made by Searle to the Combination Reply, he gives us the implicit assumption that if the robot looks and behaves sufficiently like us then we could suppose they must have mental states like ours. The assumption here is merely another way of saying functionalism.',

            'After that, here comes the tricky and interesting point. He says that once we know independently how to account for its behavior without such assumptions, we would not attribute intentionality to it, especially if we knew it had a formal program. Together with his comments against the Other Minds Reply, we know that this thesis is the premise of attributing cognitive states to computers, apes or other human. In short, the implicit assumption above will be abandoned if and only if we find the evidence which is able to prove something is the instantiation of programs.',

            'I strongly agree with Searle that Other Mind Reply misses the point. Hence, instead of treating the Combination Reply and Other Mind Reply as the objection to the Chinese Room Argument, we may treat them as the application of it. Once we accept the Chinese Room Argument, we should never abandon the probability that parts or even all of people around us are built by programs and wrongly attributed consciousness by us. The Documentary Hypothesis above states this situation in a very precise way. These imagined androids are simply followed numerous instructions with outputs and inputs, but we just roughly consider them as conscious creatures. The imagined existence of them builds a serious barrier between us.',

            'Then, we should consider the Simulation Argument suggested by Nick Bostrom. To be specific, the simulation here represents the ancestor simulation. In the future, sociologists and historians can evaluate their theories or find out more evidences in the simulation of past history. For example, they run the simulation on their computers starting in 2016 in order to know the impact that if Hillary Clinton won the election of 45th president of USA instead of Donald Trump.',

            'Nick claims that there are only three probabilities of the simulation technology. First, our civilization goes extinct before that technology has been invented. Second, we are not interested in running the ancestor simulations or we think it is unethical to do so even we have developed that. Third, we are certainly living in a simulation.',

            'We may change the definition of simulation from ancestor simulation to unlimited simulation. Unlimited simulation is like the way we simulate the motivation of clouds and winds on the supercomputers to predict weather, which means that it is unnecessary for any consistency between the simulators and the simulated products.',

            'The Unlimited Simulation Argument provides us a stronger conclusion but required a stricter premise. Supposed that one day we reach the edge that we are able to simulate a human or even the entire society in computer, we must admit that it is almost impossible that we are the first generation in the simulation chain. Instead, we are largely possible in one of the nodes of the infinite simulation chain. Taking infinite time, we could clearly see the infinite simulation chain that the simulators of our world are also simulated while the world we created in our computers will develop their simulation technology.',

            'Before discussing what the simulation arguments will bring to us, I want to figure out that the judgement on whether we successfully stimulate a human in the computer is nearly the same as the judgment on whether the computer has consciousness. Although we have made various simulations of our society and human in video games and sociology models, the point here is how to confirm these results we had made and evaluate the distance between them and the real stimulation. In other words, we may already have successfully simulated a weak version of human in computer now, but we cannot notice and improve it until more principles of conciseness discovered. Of course, we could presuppose that we do find the way to confirm the success of the simulation in the future, which won\'t make any difference to the argument.',

            'In the simulation arguments, we reach the point that we are most likely living in a simulation where everything in this world is built by computational processes including our mind. The simulators may or may not be totally different from us and the reality they have may or may not have nearly no relation with the world we are living.',

            'Finally, we are at the first step of the path. Rather than considering whether we should attribute consciences to others who are in fact documentary androids, we should now doubt whether we ourselves are conscious under the circumstance of simulation arguments. If we accept the Chinese Room Argument, we must conclude that intentionality is wrongly attributed to ourselves and we are not conscious because we are fundamentally the instantiation of programs.',

            'Does that mean that the Chinese Room Argument and the Simulation Arguments have inner conflict? Or we should embrace the conclusion that consciousness is an illusion. The problem is that neither our feeling of the existence of our own consciousness nor these arguments give us positive and direct definition of it. All of them don\'t give us a good enough source where consciousness comes from and the principles that used to distinguish different states of consciousness and non-consciousness.',

            'My goal here is not giving a skeptical conclusion that the existence of consciousness is an illusion. Instead, I want to argue that the path from that we ourselves are conscious to that complex computers are conscious is not that coherent as we thought under the analysis. The gaps between these three steps are strongly relevant to the essence of consciousness remained unexplored.'],
    },
];

export default data;
